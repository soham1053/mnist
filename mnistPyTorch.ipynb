{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.00003\n",
    "loss_beta = 0.99\n",
    "loss_running_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./files/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./files/MNIST\\raw\\train-images-idx3-ubyte.gz to ./files/MNIST\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./files/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./files/MNIST\\raw\\train-labels-idx1-ubyte.gz to ./files/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./files/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./files/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./files/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./files/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%c:\\python38\\lib\\site-packages\\torchvision\\datasets\\mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./files/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./files/MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Ground Truth: 1')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exampleIndex = np.random.randint(1000)\n",
    "plt.imshow(example_data[exampleIndex][0], cmap='gray', interpolation='none')\n",
    "plt.title(\"Ground Truth: {}\".format(example_targets[exampleIndex]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 3, 5)\n",
    "        self.pool = nn.MaxPool2d(2, stride=1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(3*23*23, 16)\n",
    "        self.fc2 = nn.Linear(16, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = x.view(-1, 3*23*23)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 3, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=1587, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.kaiming_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "net = Net()\n",
    "net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1 Loss Running Average: 0.6519467448456459\n",
      "Epoch #2 Loss Running Average: 0.39093879215861416\n",
      "Epoch #3 Loss Running Average: 0.31397212469192115\n",
      "Epoch #4 Loss Running Average: 0.2737799133963821\n",
      "Epoch #5 Loss Running Average: 0.24097124975487463\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "t = 0\n",
    "for epoch in range(n_epochs):\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):        \n",
    "        t += 1\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        loss_running_avg = loss_beta * loss_running_avg + (1-loss_beta) * loss.item()\n",
    "        losses.append(loss_running_avg / (1 - loss_beta**t))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch #{epoch+1} Loss Running Average: {loss_running_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "    outputs = torch.argmax(net(inputs), dim=1)\n",
    "    n_correct = (outputs==targets).sum().item()\n",
    "    accuracy = n_correct/batch_size_test\n",
    "    accs.append(accuracy)\n",
    "print(f\"Test Accuracy: {sum(accs)/len(accs)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
